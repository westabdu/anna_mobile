# src/api/groq.py - MODEL ADI DÃœZELTÄ°LDÄ°
import os
from groq import Groq
from dotenv import load_dotenv

load_dotenv()

class GroqAI:
    """Groq API ile ultra hÄ±zlÄ± yapay zeka"""
    
    def __init__(self):
        self.api_key = os.getenv("GROQ_API_KEY")
        self.client = None
        self.available = False
        self.current_model = "llama-3.3-70b-versatile"  # GÃœNCELLENMÄ°Å MODEL
        
        if self.api_key:
            try:
                self.client = Groq(api_key=self.api_key)
                self.available = True
                print(f"âœ… Groq AI hazÄ±r (Model: {self.current_model})")
            except Exception as e:
                print(f"âŒ Groq baÅŸlatÄ±lamadÄ±: {e}")
                self.available = False
        else:
            print("âš ï¸ GROQ_API_KEY bulunamadÄ±")
    
    def ask(self, prompt: str) -> str:
        """Soru sor (gÃ¼ncel model ile)"""
        if not self.available or not self.client:
            return "Groq API hazÄ±r deÄŸil."
        
        try:
            completion = self.client.chat.completions.create(
                model=self.current_model,  # GÃ¼ncellenmiÅŸ model adÄ±
                messages=[
                    {
                        "role": "system", 
                        "content": "Sen A.N.N.A'sÄ±n. YardÄ±msever, zeki ve karizmatik bir asistansÄ±n. CevaplarÄ±n kÄ±sa ve Ã¶z olsun."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.6,
                max_tokens=1024
            )
            return completion.choices[0].message.content
        except Exception as e:
            # Hata durumunda alternatif model dene
            if "decommissioned" in str(e) or "deprecated" in str(e):
                return self._try_alternative_model(prompt)
            return f"âŒ Groq hatasÄ±: {e}"
    
    def _try_alternative_model(self, prompt: str) -> str:
        """Alternatif modelleri dene"""
        alternative_models = [
            "llama-3.1-8b-instant",
            "mixtral-8x7b-32768",
            "gemma2-9b-it"
        ]
        
        for model in alternative_models:
            try:
                print(f"ğŸ”„ Alternatif model deneniyor: {model}")
                completion = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "Sen A.N.N.A'sÄ±n, yardÄ±msever bir asistansÄ±n."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.6,
                    max_tokens=1024
                )
                self.current_model = model  # BaÅŸarÄ±lÄ± olan modeli kaydet
                print(f"âœ… Yeni model aktif: {model}")
                return completion.choices[0].message.content
            except:
                continue
        
        return "âŒ TÃ¼m Groq modelleri denendi ama hiÃ§biri Ã§alÄ±ÅŸmadÄ±. LÃ¼tfen daha sonra tekrar deneyin."