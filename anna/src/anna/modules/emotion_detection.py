# modules/emotion_detection.py
"""
Duygu analizi mod√ºl√º - Y√ºz ifadelerinden duygu tanƒ±ma ve UI senkronizasyonu
"""
import cv2
import numpy as np
import threading
import time
import random
from deepface import DeepFace

class EmotionDetector:
    def __init__(self):
        self.current_emotion = "neutral"
        self.emotion_history = []
        self.last_emotion_time = time.time()
        self.active = False
        self.confidence = 0.0
        self.emotions_colors = {
            "angry": "#ff4444",      # Kƒ±rmƒ±zƒ± (√∂fkeli)
            "disgust": "#8B4513",     # Kahverengi (iƒürenmi≈ü)
            "fear": "#800080",        # Mor (korkmu≈ü)
            "happy": "#FFD700",       # Sarƒ± (mutlu)
            "sad": "#4169E1",         # Mavi (√ºzg√ºn)
            "surprise": "#FFA500",    # Turuncu (≈üa≈üƒ±rmƒ±≈ü)
            "neutral": "#A9A9A9",     # Gri (n√∂tr)
            "calm": "#90EE90",        # A√ßƒ±k ye≈üil (sakin)
            "tired": "#808080"        # Koyu gri (yorgun)
        }
        
        # Duyguya g√∂re yapƒ±lacak aksiyonlar
        self.emotion_actions = {
            "angry": {
                "music": "calm music",
                "color": "#87CEEB",  # A√ßƒ±k mavi (sakinle≈ütirici)
                "message": "üò§ √ñfkeli g√∂r√ºn√ºyorsun. Sakinle≈ümek i√ßin m√ºzik a√ßayƒ±m mƒ±?"
            },
            "sad": {
                "music": "happy music",
                "color": "#FFD700",  # Sarƒ± (mutlu edici)
                "message": "üò¢ √úzg√ºn g√∂r√ºn√ºyorsun. Ne≈üelenmek i√ßin bir ≈üarkƒ± a√ßayƒ±m mƒ±?"
            },
            "tired": {
                "music": "lofi music",
                "color": "#98FB98",  # A√ßƒ±k ye≈üil
                "message": "üò¥ Yorgun g√∂r√ºn√ºyorsun. Dinlendirici m√ºzik a√ßayƒ±m mƒ±?"
            },
            "happy": {
                "music": "energetic music",
                "color": "#FF69B4",  # Pembe
                "message": "üòä Mutlu g√∂r√ºn√ºyorsun! Bu havaya uygun bir ≈üarkƒ± a√ßayƒ±m mƒ±?"
            },
            "stressed": {
                "music": "meditation music",
                "color": "#98FB98",
                "message": "üò∞ Stresli g√∂r√ºn√ºyorsun. Meditasyon m√ºziƒüi a√ßayƒ±m mƒ±?"
            }
        }
        
        print("üòä Duygu analizi mod√ºl√º hazƒ±r")
    
    def start_detection(self):
        """Duygu analizini ba≈ülat"""
        self.active = True
        threading.Thread(target=self._detect_loop, daemon=True).start()
        return "‚úÖ Duygu analizi ba≈ülatƒ±ldƒ±"
    
    def stop_detection(self):
        """Duygu analizini durdur"""
        self.active = False
        return "‚èπÔ∏è Duygu analizi durduruldu"
    
    def _detect_loop(self):
        """Ana analiz d√∂ng√ºs√º"""
        cap = cv2.VideoCapture(0)
        
        while self.active:
            ret, frame = cap.read()
            if not ret:
                continue
            
            # Her 3 saniyede bir analiz yap
            if time.time() - self.last_emotion_time > 3:
                try:
                    # DeepFace ile duygu analizi
                    result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
                    if result and len(result) > 0:
                        emotions = result[0]['emotion']
                        self.current_emotion = max(emotions, key=emotions.get)
                        self.confidence = emotions[self.current_emotion]
                        self.emotion_history.append({
                            'emotion': self.current_emotion,
                            'confidence': self.confidence,
                            'time': time.time()
                        })
                        self.last_emotion_time = time.time()
                except Exception as e:
                    print(f"Duygu analizi hatasƒ±: {e}")
            
            # Y√ºz √ßer√ßevesi ve duygu bilgisi √ßiz
            cv2.putText(frame, f"Duygu: {self.current_emotion} ({self.confidence:.1f}%)", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            cv2.imshow('A.N.N.A Duygu Analizi', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
    
    def get_emotion_color(self):
        """Duyguya g√∂re renk d√∂nd√ºr"""
        return self.emotions_colors.get(self.current_emotion, "#FFFFFF")
    
    def should_change_mood(self):
        """Duygu deƒüi≈üikliƒüi varsa true d√∂nd√ºr"""
        if len(self.emotion_history) < 2:
            return False
        
        last_two = self.emotion_history[-2:]
        return last_two[0]['emotion'] != last_two[1]['emotion']
    
    def get_suggested_action(self):
        """Duyguya g√∂re √∂nerilen aksiyon"""
        # Eƒüer 3 kez aynƒ± olumsuz duygu varsa aksiyon √∂ner
        if len(self.emotion_history) < 3:
            return None
        
        last_three = self.emotion_history[-3:]
        emotions = [e['emotion'] for e in last_three]
        
        if all(e in ["angry", "sad", "tired"] for e in emotions):
            most_common = max(set(emotions), key=emotions.count)
            return self.emotion_actions.get(most_common)
        
        return None
    
    def get_emotion_stats(self):
        """Duygu istatistiklerini d√∂nd√ºr"""
        if not self.emotion_history:
            return "Hen√ºz veri yok"
        
        total = len(self.emotion_history)
        emotion_counts = {}
        
        for e in self.emotion_history:
            emotion = e['emotion']
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1
        
        stats = "üìä **Duygu ƒ∞statistikleri**\n"
        for emotion, count in emotion_counts.items():
            percentage = (count / total) * 100
            stats += f"{emotion}: %{percentage:.1f}\n"
        
        return stats